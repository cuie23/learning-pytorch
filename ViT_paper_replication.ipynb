{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJhi3xlnFRG/DlMDB+3hft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2304716f90704d14a4071423fa2d37d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1305150acc144a39bcf8992b2605aa99",
              "IPY_MODEL_4c0b46f0192c4a8b8fbd671f4ccf626b",
              "IPY_MODEL_c043be5bd9754bd58eb0655f922f684e"
            ],
            "layout": "IPY_MODEL_3b456334d05a472aa5d2ed44aea2345e"
          }
        },
        "1305150acc144a39bcf8992b2605aa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e538036e9b6c430e921e7c98494fd3b7",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f5e3bcab904b79b71499b3e652e69b",
            "value": "100%"
          }
        },
        "4c0b46f0192c4a8b8fbd671f4ccf626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c2ca2422104a2585d4a1a293b18b0a",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e8569d139a40a49f83df4d8f3d0028",
            "value": 200
          }
        },
        "c043be5bd9754bd58eb0655f922f684e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac443250bdd54a28bded3c5de38a974c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac9048bdc02410abf12fcf98e08bce3",
            "value": " 200/200 [32:54&lt;00:00,  9.15s/it]"
          }
        },
        "3b456334d05a472aa5d2ed44aea2345e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e538036e9b6c430e921e7c98494fd3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f5e3bcab904b79b71499b3e652e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c2ca2422104a2585d4a1a293b18b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e8569d139a40a49f83df4d8f3d0028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac443250bdd54a28bded3c5de38a974c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac9048bdc02410abf12fcf98e08bce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cuie23/learning-pytorch/blob/main/ViT_paper_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following procedure from https://github.com/mrdbourke/pytorch-deep-learning/blob/main/08_pytorch_paper_replicating.ipynb\n",
        "\n",
        "Replicating https://arxiv.org/pdf/2010.11929"
      ],
      "metadata": {
        "id": "acFeHtoYufOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "r4OcMCcnCusy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "a972a6b7-d46f-42cf-d76c-18ac3656696a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-18bf08814031>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZtj6nV45Ykx",
        "outputId": "ee26f882-e03a-43fe-b24a-4c435acb0971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4356, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 4356 (delta 154), reused 120 (delta 120), pack-reused 4171 (from 3)\u001b[K\n",
            "Receiving objects: 100% (4356/4356), 654.37 MiB | 41.38 MiB/s, done.\n",
            "Resolving deltas: 100% (2584/2584), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "!git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "!mv pytorch-deep-learning/going_modular .\n",
        "!mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "!rm -rf pytorch-deep-learning\n",
        "from going_modular.going_modular import data_setup, engine\n",
        "from helper_functions import download_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BfJuNNSfuj7u",
        "outputId": "5793d21f-f925-42f6-d4f4-cc68eb72ef42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up data/dataloaders"
      ],
      "metadata": {
        "id": "mesJZKD8waKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyR_HxIQwVbc",
        "outputId": "57dd8fe4-1c62-4c28-f0ee-85e25913daa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",           # where to download data to?\n",
        "    train=True,            # get training data\n",
        "    download=True,         # download data if it doesn't exist on disk\n",
        "    transform=ToTensor()   # images come as PIL format, turn into Torch tensors\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # get test data\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False     # don't necessarily have to shuffle the testing data\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYvutD2Bi4P0",
        "outputId": "fa315193-10f1-4c25-cd19-4d07363bedc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 63.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 71.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 37.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 15.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "0DQa2F7Sjm3g",
        "outputId": "5398aa77-e8b4-4530-ea53-085c9ddd2614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-cc7dedef690e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tviCbOB4wbiJ",
        "outputId": "a5b2775f-8771-4442-eb04-a754473f1c7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16 # start with small batch size\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=transforms,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4WMlqAPxKPP",
        "outputId": "d34c4e95-a25b-4ecb-a44b-6217ea4e83ed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x796ef37aa860>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x796ef374a110>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_dataloader))\n",
        "image, label = image_batch[0], label_batch[0]\n",
        "image.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRBjIFQGpwLK",
        "outputId": "08929e51-eb32-4326-aea1-08be5546448c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), tensor(4))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rebuilding model outlined in Figure 1\n",
        "1. Patch + position embedding\n",
        "  * Partition image into subsections, turn into sequence of \"patches\"\n",
        "2. Embed patches (as a vector)\n",
        "3. Layer Normalization\n",
        "  * Regularization\n",
        "4. Multi-Head Attention\n",
        "  * Multiple attention vectors computed in parallel and combined\n",
        "5. MLP (Multi-Layer Perceptron)\n",
        "  * Typical Dense NN\n",
        "6. MLP Head\n",
        "  * \"Output Layer\", converts learned features to output vector"
      ],
      "metadata": {
        "id": "iayOpTfF0ILs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math\n",
        "* $z_0 = [x_{class}\\ ;\\ x^1_pE\\ ;\\ x^2_pE\\ ;\\ ...\\ ;\\ x^N_pE] + E_{pos}, E\\in\\mathbb{R}^{(P^2\\cdot C)\\times D}, E_{pos}\\in \\mathbb{R}^{(N+1)\\times D}$\n",
        "  * class token, patch embedding, position embedding\n",
        "  * $z_0=$  output of initial layer\n",
        "  * $E,\\ E_{pos}=$embedding/position embedding\n",
        "  * $C = $ number of channels\n",
        "  * $D=$ hidden layer size\n",
        "  * $P=$ side length of patch\n",
        "  * $N=HW/P^2=$ number of patches\n",
        "* $z'_\\ell=MSA(LN(z_{\\ell-1}))+z_{\\ell-1}$\n",
        "  * multi-head attention\n",
        "  * MSA layer wrapping Layer Norm\n",
        "  * $z'_\\ell=$ intermediary output of $\\ell^{th}$ layer\n",
        "* $z_\\ell=MLP(LN(z'_\\ell))+z'_\\ell$\n",
        "  * multi-layer perceptron\n",
        "  * MLP wrapping Layer Norm\n",
        "  * $z_\\ell=$ output of $\\ell^{th}$ layer\n",
        "* $y=LN(z^0_L)$\n",
        "  * Linear dense output layer"
      ],
      "metadata": {
        "id": "CtAk3sF64FG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables\n",
        "H = 224\n",
        "W = 224\n",
        "C = 3\n",
        "P = 16\n",
        "D = 768\n",
        "\n",
        "N = H*W / (P**2)\n",
        "\n",
        "# Embedding layer, create patches of size P\n",
        "# Output shape of\n",
        "conv2d = nn.Conv2d(in_channels=C, out_channels=D, kernel_size=P, stride=P)\n",
        "\n",
        "# Flatten layer, only flatten feature map\n",
        "flatten = nn.Flatten(start_dim = 2, end_dim = 3)"
      ],
      "metadata": {
        "id": "yClrhtNMxVVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patch Embedding"
      ],
      "metadata": {
        "id": "NwPCVCvdKpk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See shape of embedding\n",
        "# (batch_size, embedding_dim, feature_map_height, feature_map_width)\n",
        "# feature_map_width = W / P\n",
        "test_output = conv2d(image.unsqueeze(dim=0))\n",
        "test_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAYDNhpRqBBQ",
        "outputId": "39490c8c-166b-4c71-d507-e1d4ac46da7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768, 14, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten(conv2d(image.unsqueeze(dim=0))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUKELarY4Pwa",
        "outputId": "0256486b-56b2-4eec-e61f-464967ae72ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768, 196])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels:int=3,\n",
        "                 patch_size:int=16,\n",
        "                 embedding_dim:int=768):\n",
        "        super().__init__()\n",
        "\n",
        "        self.P = patch_size\n",
        "\n",
        "        # create patches\n",
        "        self.patcher = nn.Conv2d(in_channels=in_channels,\n",
        "                                 out_channels=embedding_dim,\n",
        "                                 kernel_size=self.P,\n",
        "                                 stride=self.P,\n",
        "                                 padding=0)\n",
        "\n",
        "        # flatten\n",
        "        self.flatten = nn.Flatten(start_dim=2, # only flatten feature map dimensions\n",
        "                                  end_dim=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # assertion to check that inputs are the correct shape\n",
        "        image_resolution = x.shape[-1]\n",
        "        assert image_resolution % self.P == 0\n",
        "\n",
        "        x_patched = self.patcher(x)\n",
        "        x_flattened = self.flatten(x_patched)\n",
        "\n",
        "        return x_flattened.permute(0, 2, 1) # adjust shape so final dim is correct"
      ],
      "metadata": {
        "id": "rgCEfnGGmOki"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = PatchEmbedding()\n",
        "patch_embedded = embed(image.unsqueeze(dim=0))\n",
        "\n",
        "patch_embedded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovbO7FRcKN_c",
        "outputId": "baf9572c-1733-403e-f0a0-9c708d5f2874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 196, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H = 224\n",
        "W = 224\n",
        "C = 3\n",
        "P = 16\n",
        "D = 768\n",
        "\n",
        "N = int(H*W / (P**2))\n",
        "print(N)\n",
        "\n",
        "batch_size = patch_embedded.shape[0]\n",
        "embedding_dimension = patch_embedded.shape[2]\n",
        "\n",
        "# Class token is random vector of length embedding_dimension\n",
        "class_token = nn.Parameter(torch.randn(batch_size, 1, embedding_dimension))\n",
        "\n",
        "embedded_with_token = torch.cat((class_token, patch_embedded), dim=1)\n",
        "print(embedded_with_token.shape)\n",
        "\n",
        "\n",
        "# add position embedding\n",
        "number_of_patches = int((H * W) / P**2)\n",
        "\n",
        "# Get embedding dimension\n",
        "embedding_dimension = embedded_with_token.shape[2]\n",
        "\n",
        "# Create the learnable 1D position embedding\n",
        "position_embedding = nn.Parameter(torch.randn(batch_size,\n",
        "                                             N+1,\n",
        "                                             embedding_dimension))\n",
        "\n",
        "print(position_embedding.shape)\n",
        "\n",
        "patch_position_embedded = embedded_with_token + position_embedding\n",
        "print(patch_position_embedded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTBczjZLKhad",
        "outputId": "016707f2-2270-44d5-8e84-4954ba292c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196\n",
            "torch.Size([1, 197, 768])\n",
            "torch.Size([1, 197, 768])\n",
            "torch.Size([1, 197, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSA"
      ],
      "metadata": {
        "id": "g1UOHrT4fLo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadSelfAttention(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_dim: int=768,\n",
        "               num_heads:int=12,\n",
        "               dropout=0): # paper doesn't indicate any dropout\n",
        "     super().__init__()\n",
        "\n",
        "     # Use built in pytorch laeyrs\n",
        "     self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n",
        "\n",
        "     self.multi_head_attn = nn.MultiheadAttention(embed_dim=embedding_dim,\n",
        "                                                  num_heads=num_heads,\n",
        "                                                  dropout=dropout,\n",
        "                                                  batch_first=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer_norm(x)\n",
        "    x, _ = self.multi_head_attn(query=x, # query embeddings\n",
        "                                key=x,\n",
        "                                value=x,\n",
        "                                need_weights=False)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pHjECcNbLEbP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_self_attention_block = MultiheadSelfAttention(embedding_dim=768,\n",
        "                                                             num_heads=12)\n",
        "after_msa = multihead_self_attention_block(patch_position_embedded)\n",
        "patch_position_embedded.shape, after_msa.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6IQGBp0dQOk",
        "outputId": "3d1d1033-7a3f-408d-9db9-ca0b4c28c8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 197, 768]), torch.Size([1, 197, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP\n",
        "* \"two layers with a GELU non-linearity\"\n",
        "* \"Dropout, when used, is applied after\n",
        "every dense layer except for the the qkv-projections and directly after adding positional- to patch\n",
        "embeddings\"\n",
        "* Structure is:\n",
        "  1. layer norm\n",
        "  2. linear\n",
        "  3. GELU\n",
        "  4. dropout\n",
        "  5. linear\n",
        "  6. dropout"
      ],
      "metadata": {
        "id": "dQdJ77p5fNrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_dim:int=768,\n",
        "               mlp_size: int=3072,\n",
        "               dropout:float=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n",
        "\n",
        "    self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_features=embedding_dim,\n",
        "                      out_features=mlp_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout), # probability of dropping an edge, used after every dense layer\n",
        "            nn.Linear(in_features=mlp_size,\n",
        "                      out_features=embedding_dim),\n",
        "            nn.Dropout(p=dropout)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BdzsA23ee26A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_block = MLP(embedding_dim=768,\n",
        "                     mlp_size=3072,\n",
        "                     dropout=0.1)\n",
        "\n",
        "after_mlp = mlp_block(after_msa)\n",
        "after_msa.shape,after_mlp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC_j-zFqg8HL",
        "outputId": "15807160-a641-46d4-9f8a-a62499f28ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 197, 768]), torch.Size([1, 197, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder\n",
        "\"The Transformer encoder (Vaswani et al., 2017) consists of alternating layers of multiheaded selfattention (MSA, see Appendix A) and MLP blocks (Eq. 2, 3). Layernorm (LN) is applied before every block, and residual connections after every block (Wang et al., 2019; Baevski & Auli, 2019).\"\n",
        "  * Residual connection - input is added to output"
      ],
      "metadata": {
        "id": "vjqPqMmWnjtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_dim:int=768,\n",
        "               num_heads:int=12,\n",
        "               mlp_size:int=3072,\n",
        "               mlp_dropout:float=0.1,\n",
        "               attn_dropout:float=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    # Use previously created MSA/MLP classes\n",
        "    self.msa = MultiheadSelfAttention(embedding_dim=embedding_dim,\n",
        "                                      num_heads=num_heads,\n",
        "                                      dropout=attn_dropout)\n",
        "    self.mlp = MLP(embedding_dim=embedding_dim,\n",
        "                   mlp_size=mlp_size,\n",
        "                   dropout=mlp_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.msa(x) + x # adding input (residual connection)\n",
        "    x = self.mlp(x) + x\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "a-9l-EOWhO5z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_encoder = TransformerEncoder()\n",
        "print(transformer_encoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvGaktytokgw",
        "outputId": "0bb81663-ece4-475d-dcac-a4f0c23b9c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerEncoder(\n",
            "  (msa): MultiheadSelfAttention(\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (multi_head_attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mlp): MLP(\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (mlp): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (1): GELU(approximate='none')\n",
            "      (2): Dropout(p=0.1, inplace=False)\n",
            "      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "      (4): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively use pytorch's built in transformer layer"
      ],
      "metadata": {
        "id": "1BZ0kmefqZw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=768,\n",
        "                                                             nhead=12,\n",
        "                                                             dim_feedforward=3072,    # MLP size\n",
        "                                                             dropout=0.1,             # Amount of dropout for dense layers\n",
        "                                                             activation=\"gelu\",       # GELU non-linear activation\n",
        "                                                             batch_first=True,\n",
        "                                                             norm_first=True)         # Normalize before MSA/MLP layers\n",
        "torch_transformer_encoder_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FyOOe0donQ5",
        "outputId": "8071bd58-cc64-4a3c-b70a-e01e15d9a8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoderLayer(\n",
              "  (self_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout1): Dropout(p=0.1, inplace=False)\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model"
      ],
      "metadata": {
        "id": "Y295E2CqrncX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "  # hyperparams from Tables 1 and 3\n",
        "  def __init__(self,\n",
        "              img_size:int=224,       # H/W\n",
        "              in_channels:int=3,      # C\n",
        "              patch_size:int=16,      # P\n",
        "              num_transformer_layers:int=12,\n",
        "              embedding_dim:int=768,  # D\n",
        "              mlp_size:int=3072,\n",
        "              num_heads:int=12,\n",
        "              attn_dropout:float=0,\n",
        "              mlp_dropout:float=0.1,\n",
        "              embedding_dropout:float=0.1,\n",
        "              num_classes:int=1000):\n",
        "    super().__init__()\n",
        "\n",
        "    assert img_size % patch_size == 0  # check divisibility\n",
        "\n",
        "    # Constants\n",
        "    self.num_patches = int(img_size**2 / patch_size**2)   # N\n",
        "    self.class_embedding = nn.Parameter(torch.randn(1, 1, embedding_dim), requires_grad=True)   # x_class\n",
        "    self.position_embedding = nn.Parameter(torch.randn(1, self.num_patches+1, embedding_dim), requires_grad=True)   # E_pos\n",
        "\n",
        "    # Layers\n",
        "    self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n",
        "    self.patch_embedding = PatchEmbedding(in_channels=in_channels,\n",
        "                                          patch_size=patch_size,\n",
        "                                          embedding_dim=embedding_dim)\n",
        "    self.transformer_encoder = nn.Sequential(*[TransformerEncoder(embedding_dim=embedding_dim,      # * means \"for all\", basically just follow loop\n",
        "                                                                  num_heads=num_heads,\n",
        "                                                                  mlp_size=mlp_size,\n",
        "                                                                  mlp_dropout=mlp_dropout) for _ in range(num_transformer_layers)])\n",
        "\n",
        "    self.classifier = nn.Sequential(  # aka \"MLP head\"\n",
        "            nn.LayerNorm(normalized_shape=embedding_dim),\n",
        "            nn.Linear(in_features=embedding_dim,\n",
        "                      out_features=num_classes)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        class_token = self.class_embedding.expand(batch_size, -1, -1)\n",
        "        x = self.patch_embedding(x)\n",
        "        x = torch.cat((class_token, x), dim=1)  # concat class token\n",
        "        x = self.position_embedding + x\n",
        "        x = self.embedding_dropout(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.classifier(x[:, 0])\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "w4fGx5pXqnkW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "nJiqvmuct8Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit = ViT(#img_size=28,\n",
        "          #in_channels=1,\n",
        "          #patch_size=2,\n",
        "          num_classes=len(class_names))"
      ],
      "metadata": {
        "id": "4FJQY0aIiBwn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=vit.parameters(), # default value from paper\n",
        "                             lr=3e-3,\n",
        "                             betas=(0.9, 0.999),\n",
        "                             weight_decay=0.3)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "results = engine.train(model=vit,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2304716f90704d14a4071423fa2d37d4",
            "1305150acc144a39bcf8992b2605aa99",
            "4c0b46f0192c4a8b8fbd671f4ccf626b",
            "c043be5bd9754bd58eb0655f922f684e",
            "3b456334d05a472aa5d2ed44aea2345e",
            "e538036e9b6c430e921e7c98494fd3b7",
            "c9f5e3bcab904b79b71499b3e652e69b",
            "00c2ca2422104a2585d4a1a293b18b0a",
            "c3e8569d139a40a49f83df4d8f3d0028",
            "ac443250bdd54a28bded3c5de38a974c",
            "5ac9048bdc02410abf12fcf98e08bce3"
          ]
        },
        "id": "_Bq2pbjcuaIA",
        "outputId": "a1c67246-5da0-42ef-c238-32ff1df14cbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2304716f90704d14a4071423fa2d37d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 3.4127 | train_acc: 0.2500 | test_loss: 1.7502 | test_acc: 0.2375\n",
            "Epoch: 2 | train_loss: 1.2267 | train_acc: 0.2917 | test_loss: 1.1630 | test_acc: 0.4500\n",
            "Epoch: 3 | train_loss: 1.1501 | train_acc: 0.3375 | test_loss: 1.1169 | test_acc: 0.4500\n",
            "Epoch: 4 | train_loss: 1.1399 | train_acc: 0.3292 | test_loss: 1.2340 | test_acc: 0.3125\n",
            "Epoch: 5 | train_loss: 1.1294 | train_acc: 0.4167 | test_loss: 1.4692 | test_acc: 0.2375\n",
            "Epoch: 6 | train_loss: 1.3194 | train_acc: 0.3167 | test_loss: 1.0929 | test_acc: 0.4500\n",
            "Epoch: 7 | train_loss: 1.2149 | train_acc: 0.3250 | test_loss: 1.1783 | test_acc: 0.4500\n",
            "Epoch: 8 | train_loss: 1.2402 | train_acc: 0.2750 | test_loss: 1.1911 | test_acc: 0.2375\n",
            "Epoch: 9 | train_loss: 1.2036 | train_acc: 0.3208 | test_loss: 1.0744 | test_acc: 0.4500\n",
            "Epoch: 10 | train_loss: 1.1401 | train_acc: 0.2875 | test_loss: 1.1190 | test_acc: 0.3125\n",
            "Epoch: 11 | train_loss: 1.1558 | train_acc: 0.2875 | test_loss: 1.1736 | test_acc: 0.2375\n",
            "Epoch: 12 | train_loss: 1.1306 | train_acc: 0.2708 | test_loss: 1.1737 | test_acc: 0.2375\n",
            "Epoch: 13 | train_loss: 1.1393 | train_acc: 0.2958 | test_loss: 1.0753 | test_acc: 0.4500\n",
            "Epoch: 14 | train_loss: 1.1094 | train_acc: 0.3167 | test_loss: 1.1667 | test_acc: 0.2375\n",
            "Epoch: 15 | train_loss: 1.1080 | train_acc: 0.3833 | test_loss: 1.1560 | test_acc: 0.3125\n",
            "Epoch: 16 | train_loss: 1.1549 | train_acc: 0.2667 | test_loss: 1.1140 | test_acc: 0.2375\n",
            "Epoch: 17 | train_loss: 1.1162 | train_acc: 0.3333 | test_loss: 1.0927 | test_acc: 0.3125\n",
            "Epoch: 18 | train_loss: 1.1194 | train_acc: 0.3417 | test_loss: 1.1432 | test_acc: 0.3125\n",
            "Epoch: 19 | train_loss: 1.1209 | train_acc: 0.3125 | test_loss: 1.0940 | test_acc: 0.4500\n",
            "Epoch: 20 | train_loss: 1.1153 | train_acc: 0.2958 | test_loss: 1.0867 | test_acc: 0.3125\n",
            "Epoch: 21 | train_loss: 1.1206 | train_acc: 0.2458 | test_loss: 1.1072 | test_acc: 0.3125\n",
            "Epoch: 22 | train_loss: 1.1305 | train_acc: 0.2667 | test_loss: 1.1032 | test_acc: 0.2375\n",
            "Epoch: 23 | train_loss: 1.1207 | train_acc: 0.3125 | test_loss: 1.1556 | test_acc: 0.2375\n",
            "Epoch: 24 | train_loss: 1.1042 | train_acc: 0.3792 | test_loss: 1.0973 | test_acc: 0.3125\n",
            "Epoch: 25 | train_loss: 1.1073 | train_acc: 0.3250 | test_loss: 1.0963 | test_acc: 0.3125\n",
            "Epoch: 26 | train_loss: 1.1035 | train_acc: 0.3083 | test_loss: 1.0940 | test_acc: 0.4500\n",
            "Epoch: 27 | train_loss: 1.0932 | train_acc: 0.4042 | test_loss: 1.1281 | test_acc: 0.2375\n",
            "Epoch: 28 | train_loss: 1.1031 | train_acc: 0.3125 | test_loss: 1.1252 | test_acc: 0.2375\n",
            "Epoch: 29 | train_loss: 1.1064 | train_acc: 0.3250 | test_loss: 1.1148 | test_acc: 0.3125\n",
            "Epoch: 30 | train_loss: 1.0960 | train_acc: 0.3500 | test_loss: 1.1216 | test_acc: 0.2375\n",
            "Epoch: 31 | train_loss: 1.0956 | train_acc: 0.3750 | test_loss: 1.1219 | test_acc: 0.2375\n",
            "Epoch: 32 | train_loss: 1.0974 | train_acc: 0.3750 | test_loss: 1.1238 | test_acc: 0.2375\n",
            "Epoch: 33 | train_loss: 1.1020 | train_acc: 0.3125 | test_loss: 1.1180 | test_acc: 0.2375\n",
            "Epoch: 34 | train_loss: 1.0975 | train_acc: 0.3458 | test_loss: 1.1083 | test_acc: 0.3125\n",
            "Epoch: 35 | train_loss: 1.1047 | train_acc: 0.3250 | test_loss: 1.1098 | test_acc: 0.3125\n",
            "Epoch: 36 | train_loss: 1.0999 | train_acc: 0.3250 | test_loss: 1.0974 | test_acc: 0.3125\n",
            "Epoch: 37 | train_loss: 1.0989 | train_acc: 0.3167 | test_loss: 1.0907 | test_acc: 0.4500\n",
            "Epoch: 38 | train_loss: 1.1007 | train_acc: 0.3000 | test_loss: 1.0913 | test_acc: 0.4500\n",
            "Epoch: 39 | train_loss: 1.1009 | train_acc: 0.3250 | test_loss: 1.0952 | test_acc: 0.3125\n",
            "Epoch: 40 | train_loss: 1.0977 | train_acc: 0.3875 | test_loss: 1.1015 | test_acc: 0.3125\n",
            "Epoch: 41 | train_loss: 1.1005 | train_acc: 0.3250 | test_loss: 1.1032 | test_acc: 0.3125\n",
            "Epoch: 42 | train_loss: 1.0967 | train_acc: 0.3875 | test_loss: 1.0996 | test_acc: 0.3125\n",
            "Epoch: 43 | train_loss: 1.0959 | train_acc: 0.3875 | test_loss: 1.1015 | test_acc: 0.3125\n",
            "Epoch: 44 | train_loss: 1.1004 | train_acc: 0.3250 | test_loss: 1.1014 | test_acc: 0.3125\n",
            "Epoch: 45 | train_loss: 1.0996 | train_acc: 0.3250 | test_loss: 1.1001 | test_acc: 0.3125\n",
            "Epoch: 46 | train_loss: 1.0963 | train_acc: 0.3875 | test_loss: 1.1014 | test_acc: 0.3125\n",
            "Epoch: 47 | train_loss: 1.1002 | train_acc: 0.3250 | test_loss: 1.1013 | test_acc: 0.3125\n",
            "Epoch: 48 | train_loss: 1.0994 | train_acc: 0.3250 | test_loss: 1.0996 | test_acc: 0.3125\n",
            "Epoch: 49 | train_loss: 1.0983 | train_acc: 0.3250 | test_loss: 1.1012 | test_acc: 0.3125\n",
            "Epoch: 50 | train_loss: 1.0977 | train_acc: 0.3208 | test_loss: 1.1028 | test_acc: 0.2375\n",
            "Epoch: 51 | train_loss: 1.0984 | train_acc: 0.3125 | test_loss: 1.1039 | test_acc: 0.2375\n",
            "Epoch: 52 | train_loss: 1.0973 | train_acc: 0.3750 | test_loss: 1.1043 | test_acc: 0.2375\n",
            "Epoch: 53 | train_loss: 1.0977 | train_acc: 0.3125 | test_loss: 1.1051 | test_acc: 0.2375\n",
            "Epoch: 54 | train_loss: 1.0976 | train_acc: 0.2958 | test_loss: 1.1050 | test_acc: 0.3125\n",
            "Epoch: 55 | train_loss: 1.0971 | train_acc: 0.3250 | test_loss: 1.1063 | test_acc: 0.3125\n",
            "Epoch: 56 | train_loss: 1.1010 | train_acc: 0.2958 | test_loss: 1.1065 | test_acc: 0.2375\n",
            "Epoch: 57 | train_loss: 1.1003 | train_acc: 0.3125 | test_loss: 1.1042 | test_acc: 0.2375\n",
            "Epoch: 58 | train_loss: 1.0977 | train_acc: 0.3750 | test_loss: 1.1022 | test_acc: 0.2375\n",
            "Epoch: 59 | train_loss: 1.0982 | train_acc: 0.3125 | test_loss: 1.1029 | test_acc: 0.2375\n",
            "Epoch: 60 | train_loss: 1.0976 | train_acc: 0.3458 | test_loss: 1.1028 | test_acc: 0.3125\n",
            "Epoch: 61 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1035 | test_acc: 0.3125\n",
            "Epoch: 62 | train_loss: 1.0972 | train_acc: 0.3875 | test_loss: 1.1045 | test_acc: 0.3125\n",
            "Epoch: 63 | train_loss: 1.1005 | train_acc: 0.3250 | test_loss: 1.1043 | test_acc: 0.3125\n",
            "Epoch: 64 | train_loss: 1.0999 | train_acc: 0.3250 | test_loss: 1.1025 | test_acc: 0.3125\n",
            "Epoch: 65 | train_loss: 1.0993 | train_acc: 0.3250 | test_loss: 1.1004 | test_acc: 0.3125\n",
            "Epoch: 66 | train_loss: 1.0992 | train_acc: 0.3250 | test_loss: 1.0986 | test_acc: 0.3125\n",
            "Epoch: 67 | train_loss: 1.0979 | train_acc: 0.3875 | test_loss: 1.1000 | test_acc: 0.3125\n",
            "Epoch: 68 | train_loss: 1.0973 | train_acc: 0.3875 | test_loss: 1.1010 | test_acc: 0.3125\n",
            "Epoch: 69 | train_loss: 1.0988 | train_acc: 0.3250 | test_loss: 1.1016 | test_acc: 0.3125\n",
            "Epoch: 70 | train_loss: 1.0982 | train_acc: 0.3250 | test_loss: 1.1029 | test_acc: 0.3125\n",
            "Epoch: 71 | train_loss: 1.0975 | train_acc: 0.3250 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 72 | train_loss: 1.0973 | train_acc: 0.3417 | test_loss: 1.1058 | test_acc: 0.2375\n",
            "Epoch: 73 | train_loss: 1.0980 | train_acc: 0.3125 | test_loss: 1.1064 | test_acc: 0.2375\n",
            "Epoch: 74 | train_loss: 1.0972 | train_acc: 0.3750 | test_loss: 1.1058 | test_acc: 0.2375\n",
            "Epoch: 75 | train_loss: 1.1009 | train_acc: 0.3125 | test_loss: 1.1061 | test_acc: 0.2375\n",
            "Epoch: 76 | train_loss: 1.1003 | train_acc: 0.3125 | test_loss: 1.1044 | test_acc: 0.2375\n",
            "Epoch: 77 | train_loss: 1.0977 | train_acc: 0.3750 | test_loss: 1.1023 | test_acc: 0.2375\n",
            "Epoch: 78 | train_loss: 1.0975 | train_acc: 0.3750 | test_loss: 1.1027 | test_acc: 0.2375\n",
            "Epoch: 79 | train_loss: 1.1001 | train_acc: 0.3125 | test_loss: 1.1038 | test_acc: 0.2375\n",
            "Epoch: 80 | train_loss: 1.0977 | train_acc: 0.3750 | test_loss: 1.1023 | test_acc: 0.2375\n",
            "Epoch: 81 | train_loss: 1.0973 | train_acc: 0.3750 | test_loss: 1.1034 | test_acc: 0.2375\n",
            "Epoch: 82 | train_loss: 1.0970 | train_acc: 0.3750 | test_loss: 1.1042 | test_acc: 0.2375\n",
            "Epoch: 83 | train_loss: 1.1007 | train_acc: 0.3125 | test_loss: 1.1054 | test_acc: 0.2375\n",
            "Epoch: 84 | train_loss: 1.0992 | train_acc: 0.3125 | test_loss: 1.1036 | test_acc: 0.2375\n",
            "Epoch: 85 | train_loss: 1.0984 | train_acc: 0.3125 | test_loss: 1.1030 | test_acc: 0.2375\n",
            "Epoch: 86 | train_loss: 1.0978 | train_acc: 0.3542 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 87 | train_loss: 1.0975 | train_acc: 0.3250 | test_loss: 1.1052 | test_acc: 0.3125\n",
            "Epoch: 88 | train_loss: 1.0970 | train_acc: 0.3667 | test_loss: 1.1057 | test_acc: 0.2375\n",
            "Epoch: 89 | train_loss: 1.0980 | train_acc: 0.3125 | test_loss: 1.1068 | test_acc: 0.2375\n",
            "Epoch: 90 | train_loss: 1.1009 | train_acc: 0.3125 | test_loss: 1.1060 | test_acc: 0.2375\n",
            "Epoch: 91 | train_loss: 1.0977 | train_acc: 0.2750 | test_loss: 1.1041 | test_acc: 0.3125\n",
            "Epoch: 92 | train_loss: 1.0976 | train_acc: 0.3250 | test_loss: 1.1044 | test_acc: 0.2375\n",
            "Epoch: 93 | train_loss: 1.1006 | train_acc: 0.3125 | test_loss: 1.1045 | test_acc: 0.3125\n",
            "Epoch: 94 | train_loss: 1.0984 | train_acc: 0.3250 | test_loss: 1.1021 | test_acc: 0.3125\n",
            "Epoch: 95 | train_loss: 1.0976 | train_acc: 0.3250 | test_loss: 1.1032 | test_acc: 0.2375\n",
            "Epoch: 96 | train_loss: 1.0971 | train_acc: 0.3750 | test_loss: 1.1046 | test_acc: 0.2375\n",
            "Epoch: 97 | train_loss: 1.1005 | train_acc: 0.3125 | test_loss: 1.1052 | test_acc: 0.2375\n",
            "Epoch: 98 | train_loss: 1.0988 | train_acc: 0.3125 | test_loss: 1.1033 | test_acc: 0.2375\n",
            "Epoch: 99 | train_loss: 1.0976 | train_acc: 0.3125 | test_loss: 1.1038 | test_acc: 0.3125\n",
            "Epoch: 100 | train_loss: 1.0967 | train_acc: 0.3875 | test_loss: 1.1038 | test_acc: 0.3125\n",
            "Epoch: 101 | train_loss: 1.0982 | train_acc: 0.3250 | test_loss: 1.1039 | test_acc: 0.3125\n",
            "Epoch: 102 | train_loss: 1.0964 | train_acc: 0.3875 | test_loss: 1.1049 | test_acc: 0.3125\n",
            "Epoch: 103 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1049 | test_acc: 0.3125\n",
            "Epoch: 104 | train_loss: 1.1010 | train_acc: 0.3250 | test_loss: 1.1055 | test_acc: 0.3125\n",
            "Epoch: 105 | train_loss: 1.0979 | train_acc: 0.3250 | test_loss: 1.1036 | test_acc: 0.3125\n",
            "Epoch: 106 | train_loss: 1.0975 | train_acc: 0.3875 | test_loss: 1.1046 | test_acc: 0.3125\n",
            "Epoch: 107 | train_loss: 1.0966 | train_acc: 0.3875 | test_loss: 1.1044 | test_acc: 0.3125\n",
            "Epoch: 108 | train_loss: 1.1004 | train_acc: 0.3250 | test_loss: 1.1039 | test_acc: 0.3125\n",
            "Epoch: 109 | train_loss: 1.0999 | train_acc: 0.3250 | test_loss: 1.1021 | test_acc: 0.3125\n",
            "Epoch: 110 | train_loss: 1.0974 | train_acc: 0.3875 | test_loss: 1.0998 | test_acc: 0.3125\n",
            "Epoch: 111 | train_loss: 1.0965 | train_acc: 0.3875 | test_loss: 1.1004 | test_acc: 0.3125\n",
            "Epoch: 112 | train_loss: 1.0959 | train_acc: 0.3875 | test_loss: 1.1010 | test_acc: 0.3125\n",
            "Epoch: 113 | train_loss: 1.0995 | train_acc: 0.3250 | test_loss: 1.1020 | test_acc: 0.3125\n",
            "Epoch: 114 | train_loss: 1.0990 | train_acc: 0.3250 | test_loss: 1.1024 | test_acc: 0.3125\n",
            "Epoch: 115 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1041 | test_acc: 0.3125\n",
            "Epoch: 116 | train_loss: 1.1007 | train_acc: 0.3250 | test_loss: 1.1053 | test_acc: 0.3125\n",
            "Epoch: 117 | train_loss: 1.0976 | train_acc: 0.3250 | test_loss: 1.1038 | test_acc: 0.3125\n",
            "Epoch: 118 | train_loss: 1.0973 | train_acc: 0.3208 | test_loss: 1.1043 | test_acc: 0.2375\n",
            "Epoch: 119 | train_loss: 1.0976 | train_acc: 0.3125 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 120 | train_loss: 1.0970 | train_acc: 0.3875 | test_loss: 1.1052 | test_acc: 0.3125\n",
            "Epoch: 121 | train_loss: 1.0974 | train_acc: 0.3250 | test_loss: 1.1053 | test_acc: 0.3125\n",
            "Epoch: 122 | train_loss: 1.0974 | train_acc: 0.3250 | test_loss: 1.1058 | test_acc: 0.3125\n",
            "Epoch: 123 | train_loss: 1.1009 | train_acc: 0.3542 | test_loss: 1.1066 | test_acc: 0.2375\n",
            "Epoch: 124 | train_loss: 1.0977 | train_acc: 0.3125 | test_loss: 1.1046 | test_acc: 0.2375\n",
            "Epoch: 125 | train_loss: 1.0972 | train_acc: 0.3625 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 126 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1041 | test_acc: 0.3125\n",
            "Epoch: 127 | train_loss: 1.1006 | train_acc: 0.3250 | test_loss: 1.1049 | test_acc: 0.3125\n",
            "Epoch: 128 | train_loss: 1.1001 | train_acc: 0.3250 | test_loss: 1.1029 | test_acc: 0.3125\n",
            "Epoch: 129 | train_loss: 1.0984 | train_acc: 0.3250 | test_loss: 1.1014 | test_acc: 0.3125\n",
            "Epoch: 130 | train_loss: 1.0995 | train_acc: 0.2917 | test_loss: 1.1012 | test_acc: 0.2375\n",
            "Epoch: 131 | train_loss: 1.0991 | train_acc: 0.3125 | test_loss: 1.1002 | test_acc: 0.3125\n",
            "Epoch: 132 | train_loss: 1.0987 | train_acc: 0.3250 | test_loss: 1.0983 | test_acc: 0.3125\n",
            "Epoch: 133 | train_loss: 1.0987 | train_acc: 0.2958 | test_loss: 1.0972 | test_acc: 0.4500\n",
            "Epoch: 134 | train_loss: 1.1000 | train_acc: 0.3083 | test_loss: 1.0979 | test_acc: 0.3125\n",
            "Epoch: 135 | train_loss: 1.0988 | train_acc: 0.3250 | test_loss: 1.0989 | test_acc: 0.3125\n",
            "Epoch: 136 | train_loss: 1.0990 | train_acc: 0.3250 | test_loss: 1.0985 | test_acc: 0.3125\n",
            "Epoch: 137 | train_loss: 1.0999 | train_acc: 0.2792 | test_loss: 1.1007 | test_acc: 0.2375\n",
            "Epoch: 138 | train_loss: 1.0985 | train_acc: 0.2958 | test_loss: 1.0995 | test_acc: 0.2375\n",
            "Epoch: 139 | train_loss: 1.0988 | train_acc: 0.3125 | test_loss: 1.1004 | test_acc: 0.2375\n",
            "Epoch: 140 | train_loss: 1.0979 | train_acc: 0.3667 | test_loss: 1.1012 | test_acc: 0.3125\n",
            "Epoch: 141 | train_loss: 1.0987 | train_acc: 0.3250 | test_loss: 1.1016 | test_acc: 0.3125\n",
            "Epoch: 142 | train_loss: 1.0968 | train_acc: 0.3875 | test_loss: 1.1026 | test_acc: 0.3125\n",
            "Epoch: 143 | train_loss: 1.0985 | train_acc: 0.3250 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 144 | train_loss: 1.0976 | train_acc: 0.3250 | test_loss: 1.1049 | test_acc: 0.3125\n",
            "Epoch: 145 | train_loss: 1.0974 | train_acc: 0.3000 | test_loss: 1.1052 | test_acc: 0.2375\n",
            "Epoch: 146 | train_loss: 1.1008 | train_acc: 0.3417 | test_loss: 1.1053 | test_acc: 0.3125\n",
            "Epoch: 147 | train_loss: 1.0979 | train_acc: 0.3250 | test_loss: 1.1034 | test_acc: 0.3125\n",
            "Epoch: 148 | train_loss: 1.0972 | train_acc: 0.3875 | test_loss: 1.1041 | test_acc: 0.3125\n",
            "Epoch: 149 | train_loss: 1.0977 | train_acc: 0.3250 | test_loss: 1.1044 | test_acc: 0.3125\n",
            "Epoch: 150 | train_loss: 1.1010 | train_acc: 0.3250 | test_loss: 1.1054 | test_acc: 0.3125\n",
            "Epoch: 151 | train_loss: 1.1001 | train_acc: 0.3250 | test_loss: 1.1034 | test_acc: 0.3125\n",
            "Epoch: 152 | train_loss: 1.0978 | train_acc: 0.3875 | test_loss: 1.1012 | test_acc: 0.3125\n",
            "Epoch: 153 | train_loss: 1.0985 | train_acc: 0.3250 | test_loss: 1.1007 | test_acc: 0.3125\n",
            "Epoch: 154 | train_loss: 1.0999 | train_acc: 0.3250 | test_loss: 1.1019 | test_acc: 0.3125\n",
            "Epoch: 155 | train_loss: 1.0993 | train_acc: 0.3250 | test_loss: 1.1002 | test_acc: 0.3125\n",
            "Epoch: 156 | train_loss: 1.0989 | train_acc: 0.3250 | test_loss: 1.0991 | test_acc: 0.3125\n",
            "Epoch: 157 | train_loss: 1.0981 | train_acc: 0.3875 | test_loss: 1.0979 | test_acc: 0.3125\n",
            "Epoch: 158 | train_loss: 1.0993 | train_acc: 0.3250 | test_loss: 1.0980 | test_acc: 0.3125\n",
            "Epoch: 159 | train_loss: 1.0988 | train_acc: 0.3250 | test_loss: 1.0996 | test_acc: 0.3125\n",
            "Epoch: 160 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1014 | test_acc: 0.3125\n",
            "Epoch: 161 | train_loss: 1.0974 | train_acc: 0.3958 | test_loss: 1.1030 | test_acc: 0.2375\n",
            "Epoch: 162 | train_loss: 1.0982 | train_acc: 0.3125 | test_loss: 1.1042 | test_acc: 0.2375\n",
            "Epoch: 163 | train_loss: 1.0978 | train_acc: 0.3125 | test_loss: 1.1044 | test_acc: 0.2375\n",
            "Epoch: 164 | train_loss: 1.0979 | train_acc: 0.3000 | test_loss: 1.1048 | test_acc: 0.3125\n",
            "Epoch: 165 | train_loss: 1.0969 | train_acc: 0.3875 | test_loss: 1.1060 | test_acc: 0.3125\n",
            "Epoch: 166 | train_loss: 1.0965 | train_acc: 0.3875 | test_loss: 1.1057 | test_acc: 0.3125\n",
            "Epoch: 167 | train_loss: 1.0977 | train_acc: 0.3250 | test_loss: 1.1062 | test_acc: 0.3125\n",
            "Epoch: 168 | train_loss: 1.0975 | train_acc: 0.3250 | test_loss: 1.1066 | test_acc: 0.3125\n",
            "Epoch: 169 | train_loss: 1.0970 | train_acc: 0.3250 | test_loss: 1.1073 | test_acc: 0.3125\n",
            "Epoch: 170 | train_loss: 1.0972 | train_acc: 0.3000 | test_loss: 1.1082 | test_acc: 0.2375\n",
            "Epoch: 171 | train_loss: 1.1013 | train_acc: 0.3000 | test_loss: 1.1069 | test_acc: 0.3125\n",
            "Epoch: 172 | train_loss: 1.1005 | train_acc: 0.3250 | test_loss: 1.1045 | test_acc: 0.3125\n",
            "Epoch: 173 | train_loss: 1.0997 | train_acc: 0.3250 | test_loss: 1.1020 | test_acc: 0.3125\n",
            "Epoch: 174 | train_loss: 1.0980 | train_acc: 0.3875 | test_loss: 1.0997 | test_acc: 0.3125\n",
            "Epoch: 175 | train_loss: 1.0972 | train_acc: 0.3875 | test_loss: 1.1002 | test_acc: 0.3125\n",
            "Epoch: 176 | train_loss: 1.0966 | train_acc: 0.3875 | test_loss: 1.1014 | test_acc: 0.3125\n",
            "Epoch: 177 | train_loss: 1.1002 | train_acc: 0.3250 | test_loss: 1.1017 | test_acc: 0.3125\n",
            "Epoch: 178 | train_loss: 1.0993 | train_acc: 0.3250 | test_loss: 1.1002 | test_acc: 0.3125\n",
            "Epoch: 179 | train_loss: 1.0995 | train_acc: 0.3250 | test_loss: 1.1006 | test_acc: 0.3125\n",
            "Epoch: 180 | train_loss: 1.0991 | train_acc: 0.3250 | test_loss: 1.0994 | test_acc: 0.3125\n",
            "Epoch: 181 | train_loss: 1.0977 | train_acc: 0.3875 | test_loss: 1.1007 | test_acc: 0.3125\n",
            "Epoch: 182 | train_loss: 1.0969 | train_acc: 0.3875 | test_loss: 1.1017 | test_acc: 0.3125\n",
            "Epoch: 183 | train_loss: 1.0988 | train_acc: 0.3250 | test_loss: 1.1017 | test_acc: 0.3125\n",
            "Epoch: 184 | train_loss: 1.0981 | train_acc: 0.3250 | test_loss: 1.1034 | test_acc: 0.3125\n",
            "Epoch: 185 | train_loss: 1.0967 | train_acc: 0.3875 | test_loss: 1.1045 | test_acc: 0.3125\n",
            "Epoch: 186 | train_loss: 1.0979 | train_acc: 0.3250 | test_loss: 1.1046 | test_acc: 0.3125\n",
            "Epoch: 187 | train_loss: 1.0975 | train_acc: 0.3250 | test_loss: 1.1064 | test_acc: 0.3125\n",
            "Epoch: 188 | train_loss: 1.0970 | train_acc: 0.3250 | test_loss: 1.1066 | test_acc: 0.2375\n",
            "Epoch: 189 | train_loss: 1.1011 | train_acc: 0.3125 | test_loss: 1.1072 | test_acc: 0.2375\n",
            "Epoch: 190 | train_loss: 1.0968 | train_acc: 0.3750 | test_loss: 1.1055 | test_acc: 0.2375\n",
            "Epoch: 191 | train_loss: 1.0968 | train_acc: 0.3750 | test_loss: 1.1056 | test_acc: 0.2375\n",
            "Epoch: 192 | train_loss: 1.0984 | train_acc: 0.3125 | test_loss: 1.1067 | test_acc: 0.2375\n",
            "Epoch: 193 | train_loss: 1.0969 | train_acc: 0.3750 | test_loss: 1.1065 | test_acc: 0.2375\n",
            "Epoch: 194 | train_loss: 1.1010 | train_acc: 0.3125 | test_loss: 1.1065 | test_acc: 0.2375\n",
            "Epoch: 195 | train_loss: 1.0979 | train_acc: 0.3125 | test_loss: 1.1046 | test_acc: 0.2375\n",
            "Epoch: 196 | train_loss: 1.0978 | train_acc: 0.2750 | test_loss: 1.1040 | test_acc: 0.3125\n",
            "Epoch: 197 | train_loss: 1.0978 | train_acc: 0.3083 | test_loss: 1.1050 | test_acc: 0.2375\n",
            "Epoch: 198 | train_loss: 1.0974 | train_acc: 0.3167 | test_loss: 1.1053 | test_acc: 0.3125\n",
            "Epoch: 199 | train_loss: 1.0969 | train_acc: 0.3875 | test_loss: 1.1055 | test_acc: 0.3125\n",
            "Epoch: 200 | train_loss: 1.0965 | train_acc: 0.3875 | test_loss: 1.1056 | test_acc: 0.3125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "all_X, all_y = [], []\n",
        "for X, y in test_dataloader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    all_X.append(X)  # Append each batch\n",
        "    all_y.append(y)\n",
        "\n",
        "X_test = torch.cat(all_X, dim=0)\n",
        "y_test = torch.cat(all_y, dim=0)\n",
        "\n",
        "final_preds = vit(X_test)\n",
        "\n",
        "print(classification_report(y_test.cpu().numpy(), final_preds.argmax(dim = 1).cpu().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOwSSNVAgwI6",
        "outputId": "117d57e0-5012-45d4-a61f-9fb457dd80f4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50        25\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.33        75\n",
            "   macro avg       0.11      0.33      0.17        75\n",
            "weighted avg       0.11      0.33      0.17        75\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "sU38A4LYAxpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31fd11e-23f4-4a4d-8a42-28d9b118e181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 31 02:36:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0              34W /  70W |  15073MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary(device=torch.device('cuda')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJykgiecCSWd",
        "outputId": "5230ad37-d03a-4c1b-f747-89e0287df51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  14732 MiB |  14751 MiB |   4680 GiB |   4666 GiB |\n",
            "|       from large pool |  14708 MiB |  14726 MiB |   4648 GiB |   4634 GiB |\n",
            "|       from small pool |     24 MiB |     51 MiB |     32 GiB |     32 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  14732 MiB |  14751 MiB |   4680 GiB |   4666 GiB |\n",
            "|       from large pool |  14708 MiB |  14726 MiB |   4648 GiB |   4634 GiB |\n",
            "|       from small pool |     24 MiB |     51 MiB |     32 GiB |     32 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |  14636 MiB |  14655 MiB |   4652 GiB |   4638 GiB |\n",
            "|       from large pool |  14612 MiB |  14630 MiB |   4620 GiB |   4605 GiB |\n",
            "|       from small pool |     24 MiB |     51 MiB |     32 GiB |     32 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  14932 MiB |  14932 MiB |  16164 MiB |   1232 MiB |\n",
            "|       from large pool |  14906 MiB |  14906 MiB |  16102 MiB |   1196 MiB |\n",
            "|       from small pool |     26 MiB |     58 MiB |     62 MiB |     36 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 203924 KiB | 664248 KiB |   3127 GiB |   3127 GiB |\n",
            "|       from large pool | 202510 KiB | 662932 KiB |   3093 GiB |   3092 GiB |\n",
            "|       from small pool |   1414 KiB |   9076 KiB |     34 GiB |     34 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |    1417    |    1418    |  597295    |  595878    |\n",
            "|       from large pool |     566    |     567    |  347144    |  346578    |\n",
            "|       from small pool |     851    |     904    |  250151    |  249300    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |    1417    |    1418    |  597295    |  595878    |\n",
            "|       from large pool |     566    |     567    |  347144    |  346578    |\n",
            "|       from small pool |     851    |     904    |  250151    |  249300    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     247    |     275    |     296    |      49    |\n",
            "|       from large pool |     234    |     246    |     265    |      31    |\n",
            "|       from small pool |      13    |      29    |      31    |      18    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     107    |     145    |  288794    |  288687    |\n",
            "|       from large pool |      72    |     126    |  214246    |  214174    |\n",
            "|       from small pool |      35    |      49    |   74548    |   74513    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vbzUsidxkvT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}